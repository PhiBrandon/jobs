SKills:

Bachelorâ€™s degree, or equivalent experience, in Computer Science, Engineering, Mathematics, or a related technical field
3+ years of experience in data engineering, data platforms, BI or related domain
Experience in successfully implementing data-centric applications, such as data warehouses, operational data stores, and data integration projects
Experience with large-scale production relational and NoSQL databases
Experience with data modelling
General understanding of data architectures and event-driven architectures
Proficient in SQL
Familiarity with one scripting language, preferably Python
Experience with Apache Airflow
Solid understanding of cloud data services: AWS services such as S3, Athena, EC2, RedShift, EMR (Elastic MapReduce), EKS, RDS (Relational Database Services) and Lambda

Responsibilities:

Design, develop and maintain scalable batch ETL and near-real-time data pipelines and architectures for various parts of our business, on fast and versatile data sources with millions of changes per day
Ensure all data provided is of the highest quality, accuracy, and consistency
Identify, design, and implement internal process improvements for optimising data delivery and re-designing infrastructure for greater scalability
Builds out new API integrations to support continuing increases in data volume and complexity
Communicate with data scientist, MLOps engineers, product owners and BI analysts in order to understand business processes and system architecture for specific product features

URL:https://www.indeed.com/rc/clk?jk=2d1de91e6e9422b6&from=jasx&tk=1hdea8ee5ipb2801&vjs=3
