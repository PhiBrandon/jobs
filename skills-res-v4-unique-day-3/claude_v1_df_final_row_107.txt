 Here are the key skills and responsibilities extracted from the job description:

Skills:
- 3+ years of experience architecting, implementing, and supporting data infrastructure and topologies
- Experience building and operating highly available, distributed systems of extraction, ingestion, and processing of large data sets 
- Experience with data warehousing, methodologies, modeling techniques, design patterns, and technologies
- Experience with data migration tools and deploying cloud-based solutions
- Advanced SQL skills
- Coding ability in R, Python, and Shell Scripting to build and deploy Pipelines
- Working knowledge of Git or similar code management software  
- Experience with data integration tools such as FiveTran, DBT, Informatica, Matillion, or similar ETL/ELT tools
- Knowledge of product features: IAAS, PAAS and SAAS solutions

Responsibilities:
- Develop and maintain data sources within the enterprise data warehouse
- Assist with data architecture, storage, integration, quality, and model recommendations  
- Contribute to design sessions and build data models to clean and transform datasets
- Assist with ETL, ELT, and reverse-ETL design, development, testing, and performance tuning
- Create and maintain data model standards including MDM
- Migrate workloads to Snowflake using industry standards
- Automate and deploy cloud-based workloads
- Design, deliver cloud native, hybrid, and multi-cloud workloads
- Maintain documentation of systems, architecture, and changes
- Design and support production job schedules, monitoring, and performance tuning
- Build automated, scalable, and sustainable solutions minimizing defects
- Assist stakeholders with data-related technical issues
- Other duties as assigned

https://www.indeed.com/rc/clk?jk=fa2210df4da3bf9a&from=jasx&tk=1hd43k4db21ci002&vjs=3