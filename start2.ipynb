{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the CSV files\n",
    "df = pd.read_csv(\"/home/bphil/youtube/data_lake_start/dataset_indeed-scraper_2023-10-23_07-07-15.csv\")\n",
    "df.info()\n",
    "df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['salary'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in an LLM\n",
    "from langchain.llms import Bedrock\n",
    "from llama_index.llms import LangChainLLM\n",
    "from llama_index.program import LLMTextCompletionProgram, DataFrame, OpenAIPydanticProgram\n",
    "from llama_index.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel\n",
    "\n",
    "bedrock = Bedrock(model_id=\"anthropic.claude-instant-v1\", model_kwargs={\n",
    "    'max_tokens_to_sample': 8000\n",
    "})\n",
    "\n",
    "llm = LangChainLLM(llm=bedrock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class Skill(BaseModel):\n",
    "    \"\"\"Correctly extracted skill from the job description\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "class Tech(BaseModel):\n",
    "    \"\"\"Correctly extracted tech from the job description\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "class Job(BaseModel):\n",
    "    skills: List[Skill]\n",
    "    techs: List[Tech]\n",
    "\n",
    "program = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Job),\n",
    "    llm=llm,\n",
    "    prompt_template_str=(\n",
    "        \"Create the job for the following job description: {input_str}\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "description_guesses = []\n",
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    description = row['description']\n",
    "    id = row['id']\n",
    "    url = row['url']\n",
    "    # Do some pydantic work\n",
    "    try:\n",
    "        response = program(input_str=description)\n",
    "        file = open(f\"pydantic_data_output_3/{id}_{index}.txt\", \"w\", encoding=\"utf-8\")\n",
    "        file.write(\"Skills:\\n\\n\")\n",
    "        for skill in response.skills:\n",
    "            file.write(f\"{skill.name}: {skill.description}\\n\")\n",
    "        file.write(\"Technologies:\\n\\n\")\n",
    "        for tech in response.techs:\n",
    "            file.write(f\"{tech.name}: {tech.description}\\n\")\n",
    "        #file.write(f\"\\nURL:{url}\\n\")\n",
    "        file.close()\n",
    "        description_guesses.append(response)\n",
    "    except(ValueError) as e:\n",
    "        print(e)\n",
    "    # Break for test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "big_text = \"\"\n",
    "\n",
    "print(len(description_guesses))\n",
    "path = \"pydantic_data_output_3/\"\n",
    "dirs = os.listdir(path)\n",
    "print(dirs)\n",
    "for file in dirs:\n",
    "    with open(path+file, 'r', encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        big_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import conlist\n",
    "\n",
    "class TopTech(BaseModel):\n",
    "    name: str\n",
    "    references: conlist(str, min_items=1)\n",
    "\n",
    "class TopSkill(BaseModel):\n",
    "    name: str\n",
    "    references: conlist(str, min_items=1)\n",
    "\n",
    "class Top5(BaseModel):\n",
    "    skills: conlist(TopSkill, min_items=5)\n",
    "    techs: conlist(TopTech, min_items=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_top_five = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Top5),\n",
    "    llm=llm,\n",
    "    prompt_template_str=(\n",
    "        \"Create the Top 5 skills and top 5 technologies with the references that make them top 5 ranked by how many times they appear, from the following job descriptions: {input_str}\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response_2 = program_top_five(input_str=big_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = open(f\"{path}/top_five/top5.txt\", \"w\", encoding=\"utf-8\")\n",
    "file.write(\"Skills:\\n\")\n",
    "for skill in response_2.skills:\n",
    "    file.write(f\"{skill.name}\\n\")\n",
    "    print(skill)\n",
    "\n",
    "file.write(\"\\n\\nTechnologies:\\n\")\n",
    "for tech in response_2.techs:\n",
    "    file.write(f\"{tech.name}\\n\")\n",
    "    print(tech)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3 = program_top_five(input_str=big_text)\n",
    "for skill in response_3.skills:\n",
    "    print(skill)\n",
    "\n",
    "for tech in response_3.techs:\n",
    "    print(tech)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redfine structure\n",
    "class TopTech(BaseModel):\n",
    "    name: str\n",
    "    classification: str\n",
    "\n",
    "class TopSkill(BaseModel):\n",
    "    name: str\n",
    "    classification: str\n",
    "\n",
    "class Top5(BaseModel):\n",
    "    skills: conlist(TopSkill, min_items=5)\n",
    "    techs: conlist(TopTech, min_items=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_top_five_2 = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Top5),\n",
    "    llm=llm,\n",
    "    prompt_template_str=(\n",
    "        \"Create the Top 5 skills and top 5 technologies with the references that make them top 5 ranked by how many times they appear, from the following job descriptions: {input_str}\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on other directory\n",
    "big_text = \"\"\n",
    "path = \"skills-res-v6-dataengineer-day-5/\"\n",
    "dirs = os.listdir(path)\n",
    "print(dirs)\n",
    "for file in dirs:\n",
    "    if os.path.isdir(path+\"/\"+file):\n",
    "        continue\n",
    "    with open(path+\"/\"+file, 'r', encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        big_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4 = program_top_five_2(input_str=big_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4 = program_top_five_2(input_str=big_text)\n",
    "for skill in response_4.skills:\n",
    "    print(skill)\n",
    "\n",
    "for tech in response_4.techs:\n",
    "    print(tech)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    response_5 = program_top_five_2(input_str=big_text)\n",
    "    file = open(f\"{path}/top_five/top5_4_{i}.txt\", \"w\", encoding=\"utf-8\")\n",
    "    file.write(\"Skills:\\n\")\n",
    "    for skill in response_5.skills:\n",
    "        file.write(f\"{skill.name}\\n\")\n",
    "        print(skill)\n",
    "\n",
    "    file.write(\"\\n\\nTechnologies:\\n\")\n",
    "    for tech in response_5.techs:\n",
    "        file.write(f\"{tech.name}\\n\")\n",
    "        print(tech)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    response_5 = program_top_five_2(input_str=big_text)\n",
    "    file = open(f\"{path}/top_five/top5_5_{i}.txt\", \"w\", encoding=\"utf-8\")\n",
    "    file.write(\"Skills:\\n\")\n",
    "    for skill in response_5.skills:\n",
    "        file.write(f\"{skill.name}: {skill.classification}\\n\")\n",
    "        print(skill)\n",
    "\n",
    "    file.write(\"\\n\\nTechnologies:\\n\")\n",
    "    for tech in response_5.techs:\n",
    "        file.write(f\"{tech.name}: {tech.classification}\\n\")\n",
    "        print(tech)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in a.dtypes.items():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class JobClass(BaseModel):\n",
    "    key_responsibilities: str\n",
    "    education: str\n",
    "    key_requirements: str\n",
    "    job_type: str\n",
    "    experience: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_2 = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(JobClass),\n",
    "    llm=llm,\n",
    "    prompt_template_str=(\n",
    "        \"Please extract the following query into a structured data according\"\n",
    "        \" to: {input_str}.Please extract both the set of column names and a\"\n",
    "        \" set of rows.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "description_guesses = []\n",
    "for index, row in enumerate(df['description']):\n",
    "    print(index)\n",
    "    # Do some pydantic work\n",
    "    response = program(input_str=row)\n",
    "    # Break for test\n",
    "    description_guesses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
