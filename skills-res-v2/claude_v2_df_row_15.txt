 Here are the key skills and responsibilities extracted from the job description:

Skills:
- 5+ years experience in software development, data engineering or related field 
- Hands-on experience with AWS DataOps services (Lambda, Step Functions, EMR/Glue, DynamoDB)
- Hands-on SQL and non-relational data modeling experience  
- Experience with data streaming technologies (Kafka, Spark Streaming, etc)

Responsibilities:
- Designing and implementing complex data ingestion and processing pipelines
- Building API interfaces for engineering teams to interact with data pipelines
- Designing scalable multi-tenant data infrastructure and integrating heterogeneous data sources
- Interfacing with engineering and ML teams to extract, transform and load data
- Working with business and product owners to gather, analyze and understand their data processing needs