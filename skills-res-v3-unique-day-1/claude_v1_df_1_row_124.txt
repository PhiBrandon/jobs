 Here are the key skills and responsibilities extracted from the job description:

Skills:
- Python
- SQL 
- Spark
- Linux/shell scripting
- AWS services: S3, Lambda, Redshift, Lake Formation, Glue ETL, Kinesis, DMS, Glue catalog/Crawlers, Git, Jira, Airflow/Orchestration

Responsibilities:
- Build data pipelines for transferring data from source systems to AWS  
- Perform ELT/ETL processes
- Develop and maintain scalable data pipelines and new API integrations
- Collaborate to improve data models and increase data accessibility
- Implement processes to monitor data quality and ensure production data accuracy
- Write tests and contribute to documentation
- Perform data analysis to troubleshoot issues
- Design data integrations and quality framework
- Work closely with engineering, product, and analytics teams